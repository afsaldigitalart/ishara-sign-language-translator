# Ishara - Sign Language Translator  

## ğŸ“Œ Project Description  
Ishara is a real-time sign language translator that bridges the communication gap between sign language users and non-signers. It leverages machine learning and computer vision to recognize sign language gestures and convert them into text.  

## ğŸ‘¥ Team Members  
- **Sree Hari A** - Frontend Developer  
- **Afsal Shaji** - Backend Developer  
- **Abdul Ahad S** - ML Model Training  
- **Siddharth Nair** - Creatives  

## ğŸ› ï¸ Technologies Used  
- **Frontend**: Next.js, React, Tailwind CSS  
- **Backend**: Python  
- **Frameworks**: Mediapipe, TensorFlow  

## ğŸ”§ Installation  

### Clone the Repository  
```sh
git clone https://github.com/afsaldigitalart/ishara-sign-language-translator.git
cd ishara-sign-language-translator
```

### Frontend Setup  
```sh
cd frontend
npm install
npm run dev
```

### Backend Setup  
```sh
cd backend
pip install -r requirements.txt
python app.py
```

## ğŸš€ Usage Guide 

1. Open your browser and navigate to **`http://localhost:3000`**  
2. Use the interface to start translating sign language gestures into text  
3. Ensure your webcam is enabled for real-time gesture recognition


## ğŸ“· Screenshots

##### Main UI
 ![Screenshot 2025-03-11 174539](https://github.com/user-attachments/assets/0ac01d3e-aa09-4f70-9ec2-77132886a9e1)
 
##### Detection UI
![Screenshot 2025-03-11 174712](https://github.com/user-attachments/assets/529adb8d-b137-4191-bb1f-cfb6c28c50a7)


 
